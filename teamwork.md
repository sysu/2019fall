# Team Work

每个同学可以从下面的[选题](#选题)中选择题目开展团队调研、分析、设计、实现和评测工作，定期开展交流并作记录等。
专题A~

## 专题A 量子编程系统
以下两个研究方向会在每周日16点（如遇出差、假期调课等因素会临时进行调整）集中开会讨论。

###研究方向A-1：量子程序的编译优化、分析和验证
- **研究组长**：邓皓巍、张昱
- **招收人数**：2-4人
- **研究内容**：由于量子计算机在许多物理机制上相对经典计算机有很多差异，许多经典计算机中运用的编译优化算法和程序分析理论都无法直接适用。本组主要研究哪些经典的编译优化算法和程序分析理论有在量子计算机上实施的价值，以及这些算法在具体实施时是否需要调整、改变，或者进行适当的组合。为了更好的做到这一点，会尝试从量子程序中抽出一些抽象特征以利于程序的分析和优化。
  在研究中，还需要注意关注量子编程语言高层抽象的发展和设计。

###研究方向A-2：量子线路的优化和映射
- **研究组长**：李权熹、张昱
- **招收人数**：2~4人
- **研究内容**：量子系统有多种实现途径，不同实现有其不同的影响因素，如量子比特之间的连接性、量子门操作的时长和错误率、量子比特的相干时间和保真度等等。由高层编译器生成的量子线路或手工编写的量子线路往往不满足实际硬件的特征，需要进一步地优化变换和到物理量子比特的映射。本组拟研究在物理映射前后以及映射期间中对量子线路的变换方法，以期改进量子线路程序的整体效果（如执行时长、错误率等等）。本研究需要找出一些常用的量子线路模式和优化技巧，探讨其在有量子设备限制时的表现形态和应用场景，并针对映射前、映射中和映射后三种时机（之一）寻找合适方式，结合物理映射手段和硬件限制进行量子线路变换和优化。

##专题B .Net适配龙芯机器
- **研究组长**：王瑞凯、张昱
- **招收人数**：2~4人
- **现有组员**：黄业琦、任俊屹
- **研究内容**：[.Net文档](https://docs.microsoft.com/zh-cn/dotnet/)，[GitHub代码库](https://github.com/dotnet )

##专题C Python和C/C++多语言混合分析
- **研究方向**：多语言程序的静态分析/动态剖析
- **研究组长**：胡明哲（研二，导师：张昱）
- **招收人数**：2-3人
- **研究内容**：多语言软件系统可以复用已有代码、结合语言特性，在工程实践中普遍存在。包括深度学习在内的数据科学框架就大多采用Python+C/C++的架构以兼顾开发效率和性能。但是不同的语言在类型系统、异常处理、内存管理等机制上并不相同，导致多语言接口安全存在隐患。通过总结漏洞模式，结合程序分析技术可以发现漏洞，提高软件系统的安全性。
- **已有工作**：针对Python/C API的实证安全分析，通过简单的脚本对Python/C互操作的漏洞模式进行了较为全面的分析总结，在主流软件系统中找到了一些漏洞，计划在10月投稿。

##专题D 编译优化
###研究方向D-1 方舟编译器的中间表示及优化
- **研究组长**：张昱
- **招收人数**：人数不限
- **研究内容**：了解并使用[方舟编译器](https://gitee.com/harmonyos/OpenArkCompiler)，深入理解其中间表示的特点及操作接口，开展中间表示接口的改进和针对中间表示的编译优化。
 
###研究方向D-2 基于Clang/LLVM的C/C++程序分析与优化
- **研究组长**：张昱
- **招收人数**：人数不限
- **研究内容**：了解并使用[Clang](http://clang.org/)和[LLVM](http://llvm.org/)，深入理解其中间表示的特点及操作接口，开展相关的程序分析与优化工作，如程序编码规范检查、编译优化等。

##专题E 张量计算优化
###研究方向E-1 张量计算的CPU-GPU混合内存管理与优化
- **研究组长**：黄奕桐、张昱
- **招收人数**：2~4人
- **研究内容**：现有的神经网络常常使用较多的GPU内存，而基于动态计算图的深度学习框架如[PyTorch](https://pytorch.org/)、eager模式的[Tensorflow](https://tensorflow.google.cn/)、[Julia](https://julialang.org/) 语言的 [Flux](https://github.com/MikeInnes/Flux.jl) 等，由于其计算图在神经网络运行过程中动态构建，加上部分如TreeLSTM、RNN等在运行过程中结构动态变化的神经网络模型，其GPU内存管理更为困难。本小组将会研究不同深度学习框架现有的GPU内存分配机制，比较这些内存分配机制对于张量计算的时空性能影响，并尝试结合不同神经网络框架的不同架构，寻找适合各架构的GPU内存分配机制。

###研究方向E-2 神经网络模型在受限资源下的优化
- **研究组长**：郭兴、张昱
- **招收人数**：2~4人
- **研究内容**：本小组将在低端GPU设备上研究面向图像识别、无人驾驶等应用的神经网络面向在受限资源下的优化，包括量化蒸馏、浮点转定点计算等，尝试编译技术在实施这些优化变换中的应用。